{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144091ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './work_dirs/debug_show_deepsort_private/output.pkl'\n",
    "import mmcv\n",
    "results = mmcv.load(file)\n",
    "metric='track'\n",
    "logger=None\n",
    "resfile_path=None\n",
    "bbox_iou_thr=0.5\n",
    "track_iou_thr=0.5\n",
    "show_wrong_track=False\n",
    "out_dir = './work_dirs/visualization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0be0a1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'imshow_wrong_tracks' from 'mmtrack.core' (/home/PJLAB/shensanjing/files/code/mmtracking/mmtrack/core/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-34ae161928d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDATASETS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimshow_wrong_tracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco_video_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCocoVideoDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'imshow_wrong_tracks' from 'mmtrack.core' (/home/PJLAB/shensanjing/files/code/mmtracking/mmtrack/core/__init__.py)"
     ]
    }
   ],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmcv import Config\n",
    "from mmtrack.datasets import MOTChallengeDataset\n",
    "import os\n",
    "import os.path as osp\n",
    "import tempfile\n",
    "\n",
    "import mmcv\n",
    "import motmetrics as mm\n",
    "import numpy as np\n",
    "from mmcv.utils import print_log\n",
    "from mmdet.core import eval_map\n",
    "from mmdet.datasets import DATASETS\n",
    "\n",
    "from mmtrack.core import imshow_wrong_tracks, restore_result\n",
    "from mmtrack.datasets.coco_video_dataset import CocoVideoDataset\n",
    "\n",
    "config = cfg = Config.fromfile('configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py')\n",
    "dataset = build_dataset(cfg.data.val, dict(test_mode=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e0c28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import tempfile\n",
    "\n",
    "import mmcv\n",
    "import motmetrics as mm\n",
    "import numpy as np\n",
    "from mmcv.utils import print_log\n",
    "from mmdet.core import eval_map\n",
    "from mmdet.datasets import DATASETS\n",
    "\n",
    "from mmtrack.core import restore_result\n",
    "from mmtrack.datasets import CocoVideoDataset\n",
    "\n",
    "eval_results = dict()\n",
    "if isinstance(metric, list):\n",
    "    metrics = metric\n",
    "elif isinstance(metric, str):\n",
    "    metrics = [metric]\n",
    "else:\n",
    "    raise TypeError('metric must be a list or a str.')\n",
    "allowed_metrics = ['bbox', 'track']\n",
    "for metric in metrics:\n",
    "    if metric not in allowed_metrics:\n",
    "        raise KeyError(f'metric {metric} is not supported.')\n",
    "\n",
    "if 'track' in metrics:\n",
    "    resfiles, names, tmp_dir = dataset.format_results(\n",
    "        results, resfile_path, metrics)\n",
    "    print_log('Evaluate CLEAR MOT results.', logger=logger)\n",
    "    distth = 1 - track_iou_thr\n",
    "\n",
    "    accs = []\n",
    "    for name in ['MOT17-05-DPM']:\n",
    "        print(name)\n",
    "        if 'half-train' in dataset.ann_file:\n",
    "            gt_file = osp.join(dataset.img_prefix,\n",
    "                               f'{name}/gt/gt_half-train.txt')\n",
    "        elif 'half-val' in dataset.ann_file:\n",
    "            gt_file = osp.join(dataset.img_prefix,\n",
    "                               f'{name}/gt/gt_half-val.txt')\n",
    "        else:\n",
    "            gt_file = osp.join(dataset.img_prefix, f'{name}/gt/gt.txt')\n",
    "        res_file = osp.join(resfiles['track'], f'{name}.txt')\n",
    "        gt = mm.io.loadtxt(gt_file)\n",
    "        res = mm.io.loadtxt(res_file)\n",
    "        ini_file = osp.join(dataset.img_prefix, f'{name}/seqinfo.ini')\n",
    "        if osp.exists(ini_file):\n",
    "            acc, ana = mm.utils.CLEAR_MOT_M(\n",
    "                gt, res, ini_file, distth=distth)\n",
    "        else:\n",
    "            acc = mm.utils.compare_to_groundtruth(\n",
    "                gt, res, distth=distth)\n",
    "        if show_wrong_track or out_dir:\n",
    "            first_frame_id = acc.mot_events.index[0][0]\n",
    "            last_frame_id = acc.mot_events.index[-1][0]\n",
    "            count_fp, count_fn, count_idsw = 0, 0, 0\n",
    "            for frame_id in range(first_frame_id, last_frame_id + 1):\n",
    "                # events in the current frame\n",
    "                print(frame_id)\n",
    "                events = acc.mot_events.xs(frame_id)\n",
    "                cur_res = res.loc[frame_id]\n",
    "                cur_gt = gt.loc[frame_id]\n",
    "                # path of img\n",
    "                img = osp.join(dataset.img_prefix, f'{name}/img1/{frame_id:06d}.jpg')\n",
    "                fps = events[events.Type == 'FP']\n",
    "                fns = events[events.Type == 'MISS']\n",
    "                idsws = events[events.Type == 'SWITCH']\n",
    "                \n",
    "                bboxes, ids, wrong_types = [], [], []\n",
    "                for fp_index in fps.index:\n",
    "                    hid = events.loc[fp_index].HId\n",
    "                    bboxes.append([cur_res.loc[hid].X, cur_res.loc[hid].Y,\n",
    "                                   cur_res.loc[hid].X + cur_res.loc[hid].Width,\n",
    "                                   cur_res.loc[hid].Y + cur_res.loc[hid].Height,\n",
    "                                   cur_res.loc[hid].Confidence])\n",
    "                    ids.append(hid)\n",
    "                    wrong_types.append(0)\n",
    "                    count_fp += 1\n",
    "                for fn_index in fns.index:\n",
    "                    oid = events.loc[fn_index].OId\n",
    "                    bboxes.append([cur_gt.loc[oid].X, cur_gt.loc[oid].Y,\n",
    "                                   cur_gt.loc[oid].X + cur_gt.loc[oid].Width,\n",
    "                                   cur_gt.loc[oid].Y + cur_gt.loc[oid].Height,\n",
    "                                   cur_gt.loc[oid].Confidence])\n",
    "                    ids.append(-1)\n",
    "                    wrong_types.append(1)\n",
    "                    count_fn += 1\n",
    "                for idsw_index in idsws.index:\n",
    "                    hid = events.loc[idsw_index].HId\n",
    "                    bboxes.append([cur_res.loc[hid].X, cur_res.loc[hid].Y,\n",
    "                                   cur_res.loc[hid].X + cur_res.loc[hid].Width,\n",
    "                                   cur_res.loc[hid].Y + cur_res.loc[hid].Height,\n",
    "                                   cur_res.loc[hid].Confidence])\n",
    "                    ids.append(-1)\n",
    "                    wrong_types.append(2)\n",
    "                    count_idsw += 1\n",
    "                bboxes = np.asarray(bboxes, dtype=np.float32)\n",
    "                ids = np.asarray(ids, dtype=np.int32)\n",
    "                wrong_types = np.asarray(wrong_types, dtype=np.int32)\n",
    "                img = imshow_wrong_tracks(\n",
    "                    img,\n",
    "                    bboxes,\n",
    "                    ids,\n",
    "                    wrong_types,\n",
    "                    show=show_wrong_track,\n",
    "                    out_file=osp.join(out_dir, f'{name}/{frame_id:06d}.jpg'))\n",
    "        print(count_fp)\n",
    "        print(count_fn)\n",
    "        print(count_idsw)\n",
    "            \n",
    "        accs.append(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    mh = mm.metrics.create()\n",
    "\n",
    "    summary = mh.compute_many(\n",
    "        accs,\n",
    "        names=names,\n",
    "        metrics=mm.metrics.motchallenge_metrics,\n",
    "        generate_overall=True)\n",
    "    str_summary = mm.io.render_summary(\n",
    "        summary,\n",
    "        formatters=mh.formatters,\n",
    "        namemap=mm.io.motchallenge_metric_names)\n",
    "    print(str_summary)\n",
    "\n",
    "    eval_results.update({\n",
    "        mm.io.motchallenge_metric_names[k]: v['OVERALL']\n",
    "        for k, v in summary.to_dict().items()\n",
    "    })\n",
    "\n",
    "    if tmp_dir is not None:\n",
    "        tmp_dir.cleanup()\n",
    "\n",
    "if 'bbox' in metrics:\n",
    "    if isinstance(results, dict):\n",
    "        bbox_results = results['bbox_results']\n",
    "    elif isinstance(results, list):\n",
    "        bbox_results = results\n",
    "    else:\n",
    "        raise TypeError('results must be a dict or a list.')\n",
    "    annotations = [dataset.get_ann_info(info) for info in dataset.data_infos]\n",
    "    mean_ap, _ = eval_map(\n",
    "        bbox_results,\n",
    "        annotations,\n",
    "        iou_thr=bbox_iou_thr,\n",
    "        dataset=dataset.CLASSES,\n",
    "        logger=logger)\n",
    "    eval_results['mAP'] = mean_ap\n",
    "\n",
    "for k, v in eval_results.items():\n",
    "    if isinstance(v, float):\n",
    "        eval_results[k] = float(f'{(v):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d6789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
